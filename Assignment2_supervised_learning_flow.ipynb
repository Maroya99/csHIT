{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec202ada",
   "metadata": {},
   "source": [
    "# Assignment2 - Supervised Learning flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a2810",
   "metadata": {},
   "source": [
    "# Part 1 - Student details:\n",
    "* Please write the First Name and last 4 digits of the i.d. for each student. For example:\n",
    "<pre>Israel 9812</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca16486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student 1: Almog 1460\n",
    "# student 2: Michael 0027"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67c2ee-87c8-499c-a04f-1853c332f51d",
   "metadata": {},
   "source": [
    "## Part 2 - Initial Preparations \n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9d585575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b29b3454-b568-4614-8017-f15b3c59fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name, category_col_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    X = df.drop(columns=[category_col_name])\n",
    "    y = df[category_col_name]\n",
    "\n",
    "    return df, X, y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24392e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "train_file_name = 'wine_train.csv'\n",
    "category_col_name = 'target'\n",
    "\n",
    "train_df, train_X, train_y = load_dataset(train_file_name, category_col_name)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "\n",
    "test_file_name = 'wine_test.csv'\n",
    "test_df, test_X, test_y = load_dataset(test_file_name, category_col_name)\n",
    "\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print category types for statistics\n",
    "\n",
    "train_df.dtypes\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53e27610-b640-4db0-80c9-789b5f5fae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to check for missing values in given dataframe\n",
    "\n",
    "def checkMissingRows(df):\n",
    "    complete_rows = df.dropna()\n",
    "    num_complete_rows = len(complete_rows)\n",
    "    total_rows = len(df)\n",
    "    print(f\"In There are {num_complete_rows} entries out of {total_rows} containing all values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b47fe56-d611-4b28-be92-673db4d56400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ranges of different features, with outliers\n",
    "def createPlotBoxplot(df, x_col, y_col):  \n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    sns.boxplot(data=df, x=x_col, y=y_col)  \n",
    "    plt.xlabel(x_col)  \n",
    "    plt.ylabel(y_col)  \n",
    "    plt.title(f'Box Plot of {y_col} by {x_col}')  \n",
    "    plt.grid(True)  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5fa55954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check relationship between two numerical features\n",
    "def createPlotScatter(df, column1, column2, target):  \n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    plt.scatter(df[column1], df[column2], c=df[target], alpha=0.7)  \n",
    "    plt.colorbar(label=target)  \n",
    "    plt.xlabel(column1)  \n",
    "    plt.ylabel(column2)  \n",
    "    plt.title(f'Scatter Plot of {column1} vs {column2}')  \n",
    "    plt.grid(True)  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the different statistics functions\n",
    "\n",
    "createPlotBoxplot(train_df, 'target', 'color_intensity')\n",
    "createPlotScatter(train_df, 'color_intensity', 'hue', category_col_name)\n",
    "\n",
    "checkMissingRows(train_df)\n",
    "checkMissingRows(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36672a",
   "metadata": {},
   "source": [
    "## Part 3 - Experiments\n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de7d9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration of pipelines used for testing in Grid Search CV.\n",
    "\n",
    "pipelines = {\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        ('scaler', MinMaxScaler()), \n",
    "        ('model', RandomForestClassifier())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('scaler', MinMaxScaler()), \n",
    "        ('model', SVC())\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', MinMaxScaler()), \n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27d79695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign hyperparameters for each pipeline\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForestClassifier': {\n",
    "        'model__n_estimators': [25, 50, 125, 100, 150, 200],\n",
    "        'model__max_depth': [None, 5, 10, 15, 20, 25, 30]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model__C': [0.1, 1, 2, 5, 7.5, 10],\n",
    "        'model__gamma': [0.01, 0.1, 1, 2, 3, 4, 5]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model__C': [0.1, 1, 2, 5, 7.5, 10],\n",
    "        'model__solver': ['liblinear']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute GridSearchCV with 5 folds using f1 macro to determine which hyperparameters gives the highest accuracy\n",
    "# adding the results to a list\n",
    "\n",
    "results = []\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro')\n",
    "    grid_search.fit(train_X, train_y)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    cv_scores = cross_val_score(best_model, train_X, train_y, cv=5, scoring='f1_macro')\n",
    "    avg_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Parameters': grid_search.best_params_,\n",
    "        'Average CV Score': avg_cv_score\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef2e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a pandas dataframe\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d97f11",
   "metadata": {},
   "source": [
    "## Part 4 - Training \n",
    "Use the best combination of feature engineering, model (algorithm and hyperparameters) from the experiment part (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "93713ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model and hyperparameters according to the highest CV score.\n",
    "\n",
    "best_index = results_df['Average CV Score'].idxmax()\n",
    "\n",
    "best_model_name = results_df.loc[best_index, 'Model']\n",
    "best_parameters = results_df.loc[best_index, 'Best Parameters']\n",
    "\n",
    "match best_model_name:\n",
    "    case \"RandomForestClassifier\":\n",
    "        best_permutation = Pipeline([\n",
    "            ('scaler', MinMaxScaler()), \n",
    "            ('model', RandomForestClassifier(max_depth=best_parameters['model__max_depth'], \n",
    "                                             n_estimators=best_parameters['model__n_estimators'], \n",
    "                                             random_state=42))\n",
    "        ])\n",
    "    case \"SVC\":\n",
    "        best_permutation = Pipeline([\n",
    "            ('scaler', MinMaxScaler()), \n",
    "            ('model', SVC(C=best_parameters['model__C'], gamma=best_parameters['model__gamma']))\n",
    "        ])\n",
    "    case \"LogisticRegression\":\n",
    "        best_permutation = Pipeline([\n",
    "            ('scaler', MinMaxScaler()), \n",
    "            ('model', LogisticRegression(C=best_parameters['model__C'], \n",
    "                                          solver=best_parameters['model__solver']))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ab902",
   "metadata": {},
   "source": [
    "## Part 5 - Apply on test and show model performance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the best permutation of model, hyperparameters and feature engineering.\n",
    "\n",
    "best_permutation.fit(train_X, train_y)\n",
    "prediction_y = best_permutation.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score, confusion matrix and calssification report.\n",
    "\n",
    "val_accuracy_scaled = accuracy_score(test_y, prediction_y)\n",
    "\n",
    "print(f\"Accuracy is {val_accuracy_scaled * 100}%!\\n\")\n",
    "print(confusion_matrix(test_y, prediction_y))\n",
    "print(classification_report(test_y, prediction_y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
